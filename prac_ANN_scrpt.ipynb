{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTACIÓN DE UNA RED NEURONAL ARTIFICIAL PARA LA CLASIFICACIÓN DE IMÁGENES DE SATÉLITE EN R\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### REDES NEURONALES ARTIFICIALES EN INGENIERÍA HIDRÁULICA\n",
    "\n",
    "MASTER UNIVERSITARIO EN INGENIERÍA HIDRÁULICA Y MEDIO AMBIENTE\n",
    "\n",
    "Universitat Politècnica de València\n",
    "\n",
    "Sergio Morell Monzo: sermonmo@doctor.upv.es\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESUMEN\n",
    "\n",
    "El siguiente texto describe el proceso seguido para realizar la clasificación de una imágen satelital Sentinel-2 entre dos tipos de coberturas: \"suelo desnudo\" y \"cultivo\". Para ello se ha utilizado una imagen Sentinel-2 del verano de 2018,  con código: S2B_MSIL1C_20180824T105019_N0206_R051_T30SYJ_20180824T151058. La imagen ha sido clasificada mediante la implementación de una Red Neuronal Artificial a través de la libreria \"H2O\" en lenguaje R. Las variables de entrada de la red han sido las bandas 2, 3, 4 y 8 de la imagen, todas ellas en una resolución de 10x10 metros.\n",
    "\n",
    "El esquema de utilizado ha sido el siguiente:\n",
    "\n",
    "<img src=\"images/esquema_proceso_rna_s2.png\">\n",
    "\n",
    "Figura 1: Esquema del proceso a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PREPROCESAMIENTO\n",
    "\n",
    "CORRECCIÓN ATMOSFÉRICA\n",
    "\n",
    "Para realizar la corrección atmosférica de la imagen se ha utilizado el software Sen2Cor 02.05.05 de la Agencia Espacial Europea. Sen2Cor se ha ejecutado a través de una linea de comandos en Windows para realizar la corrección atmosférica de la imagen nivel L1C a nivel L2A. La imagen con nivel de corrección L2A contiene los valores de Reflectancia de la superficie terrestre. El algoritmo utilizado realiza la corrección de cada una de las bandas de la imagen a todos los niveles de resolución posibles (60m, 20m y 10m). Las bandas con una resolución de 10m son las bandas B2, B3, B4 y B8 (Pancromática)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C:\\Users\\User>cd C:\\Sen2Cor-02.05.05-win64\n",
    "\n",
    "C:\\Sen2Cor-02.05.05-win64>L2A_Process.bat D:\\S2B_MSIL1C_20180824T105019_N0206_R051_T30SYJ_20180824T151058.SAFE\n",
    "\n",
    "pause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTALACIÓN DE LIBRERIAS\n",
    "\n",
    "No todas las librerias son necesarias para realizar esta clasificación. Algunas de ellas solamente son necesarias para realizar la clasificación mediante otros clasificadores como Random Forest y Support Vector Machine peroel código para implementar estos clasificadores no se muestra en este trabajo. A continuación se muestran todas las librerias instaladas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instalacion de librerias\n",
    "\n",
    "install.packages(\"sp\")\n",
    "install.packages(\"raster\")\n",
    "install.packages(\"rgdal\")\n",
    "install.packages(\"gdalUtils\")\n",
    "install.packages(\"caret\")\n",
    "install.packages(\"snow\")\n",
    "install.packages(\"e1071\")\n",
    "install.packages(\"h2o\")\n",
    "\n",
    "# carga de librerias\n",
    "\n",
    "library(sp)\n",
    "library(raster)\n",
    "library(rgdal)\n",
    "library(gdalUtils)\n",
    "library(caret)\n",
    "library(snow)\n",
    "library(e1071)\n",
    "library(h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINICIÓN DE DIRECTORIO DE TRABAJO\n",
    "\n",
    "Se ha creado una carpeta en D:/prac_ANN que contiene las cuatro bandas B2, B3, B4 y B8 de Sentinel-2 L2A en formato (.jp2). Estos archivos se obtienen después de realizar la corrección atmosférica en la ruta D:\\ S2B_MSIL2A_20180824T105019_N0206_R051_T30SYJ_20180824T151058.SAFE\\GRANULE\\L2A_T30SYJ_A007656_20180824T105058\\IMG_DATA\\R10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directorio de trabajo\n",
    "\n",
    "setwd(\"D:/prac_ANN\") \n",
    "\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERSIÓN DE LAS IMAGENES A FORMATO (.TIF) GEOTTIF\n",
    "\n",
    "A continuación se convierten cada una de las bandas a formato .tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdal_translate(\"banda02.jp2\", \"banda02_uncut.tif\")\n",
    "\n",
    "gdal_translate(\"banda03.jp2\", \"banda03_uncut.tif\")\n",
    "\n",
    "gdal_translate(\"banda04.jp2\", \"banda04_uncut.tif\")\n",
    "\n",
    "gdal_translate(\"banda08.jp2\", \"banda08_uncut.tif\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECORTE DE LA ZONA DE ESTUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zona de estudio\n",
    "\n",
    "zona_estudio <- readOGR(\"D:/prac_ANN/zona_estudio/zona_estudio.shp\")\n",
    "\n",
    "banda02_uncut <- raster(\"banda02_uncut.tif\")\n",
    "banda02 <- crop(banda02_uncut, zona_estudio)\n",
    "writeRaster(banda02, \"banda02.tif\", drivername=\"Gtiff\")\n",
    "\n",
    "banda03_uncut <- raster(\"banda03_uncut.tif\")\n",
    "banda03 <- crop(banda03_uncut, zona_estudio)\n",
    "writeRaster(banda03, \"banda03.tif\", drivername=\"Gtiff\")\n",
    "\n",
    "banda04_uncut <- raster(\"banda04_uncut.tif\")\n",
    "banda04 <- crop(banda04_uncut, zona_estudio)\n",
    "writeRaster(banda04, \"banda04.tif\", drivername=\"Gtiff\")\n",
    "\n",
    "banda08_uncut <- raster(\"banda08_uncut.tif\")\n",
    "banda08 <- crop(banda08_uncut, zona_estudio)\n",
    "writeRaster(banda08, \"banda08.tif\", drivername=\"Gtiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPOSICIÓN DEL RASTER MULTIBANDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# composicion raster multibanda\n",
    "\n",
    "lay1 <- (\"banda02.tif\")\n",
    "lay2 <- (\"banda03.tif\")\n",
    "lay3 <- (\"banda04.tif\")\n",
    "lay4 <- (\"banda08.tif\")\n",
    "\n",
    "comp_mult_ST <- stack(lay1, lay2, lay3, lay4, lay5, lay6)\n",
    "\n",
    "comp_mult_BR <- brick(comp_mult_ST)\n",
    "\n",
    "writeRaster(comp_mult_BR, \"comp_multi2348.tif\", drivername=\"Gtiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREACIÓN DEL DATASET (data.frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# raster multibanda\n",
    "\n",
    "img <- brick(\"comp_multi2348.tif\")\n",
    "\n",
    "img\n",
    "\n",
    "# rois de entrenamiento\n",
    "\n",
    "trainData <- shapefile(\"D:/s2_img/datos_entrenamiento/datos_entrenamiento.shp\")\n",
    "responseCol <- \"class\" #el shapefile debe contener un unico campo con nombre \"class\"\n",
    "\n",
    "trainData\n",
    "\n",
    "# extraccion de valores de pixel en las areas de entrenamiento\n",
    "\n",
    "dfAll = data.frame(matrix(vector(), nrow = 0, ncol = length(names(img)) + 1))   \n",
    "for (i in 1:length(unique(trainData[[responseCol]]))){\n",
    "  category <- unique(trainData[[responseCol]])[i]\n",
    "  categorymap <- trainData[trainData[[responseCol]] == category,]\n",
    "  dataSet <- extract(img, categorymap)\n",
    "  if(is(trainData, \"SpatialPointsDataFrame\")){\n",
    "    dataSet <- cbind(dataSet, class = as.numeric(rep(category, nrow(dataSet))))\n",
    "    dfAll <- rbind(dfAll, dataSet[complete.cases(dataSet),])\n",
    "  }\n",
    "  if(is(trainData, \"SpatialPolygonsDataFrame\")){\n",
    "    dataSet <- dataSet[!unlist(lapply(dataSet, is.null))]\n",
    "    dataSet <- lapply(dataSet, function(x){cbind(x, class = as.numeric(rep(category, nrow(x))))})\n",
    "    df <- do.call(\"rbind\", dataSet)\n",
    "    dfAll <- rbind(dfAll, df)\n",
    "  }\n",
    "}\n",
    "\n",
    "# nombre de variables\n",
    "names(dfAll) = c(\"B2\", \"B3\", \"B4\", \"B8\", \"class\")\n",
    "\n",
    "dfAll\n",
    "\n",
    "# conversion variable 'class' a tipo factor\n",
    "class(dfAll$class)\n",
    "dfAll$class <- factor(dfAll$class, levels = c(\"0\", \"1\"), labels = c(\"desnudo\", \"cultivo\"))\n",
    "class(dfAll$class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no es necesario normalizar los datos ya que las variables B2, B3, B4 y B8 estan en niveles de reflectancia (%), que es una variable adimensional y todos los registros están entre el mismo rango de valores.\n",
    "\n",
    "A pesar de ello podemos tipificar los datos restando la media y dividiendo entre la desviación estandar. Este proceso es realizado por la función \"scale\" de R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NORMALIZACION DE LOS DATOS\n",
    "library(ggplot2)\n",
    "\n",
    "#b2\n",
    "qqnorm(dfAll$B2, main= \"B2\") # Distribucion de la variable B2 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B2)\n",
    "\n",
    "#b3\n",
    "qqnorm(dfAll$B3, main= \"B3\") # Distribucion de la variable B3 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B3)\n",
    "\n",
    "#b4\n",
    "qqnorm(dfAll$B4, main= \"B4\") # Distribucion de la variable B4 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B4)\n",
    "\n",
    "#b8\n",
    "qqnorm(dfAll$B8, main= \"B8\") # Distribucion de la variable B8 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B8)\n",
    "\n",
    "# normalizar (funcion scale)\n",
    "dfAll[, c(1:4)] <- scale(dfAll[, c(1:4)])\n",
    "\n",
    "#b2\n",
    "qqnorm(dfAll$B2, main= \"B2\") # Distribucion de la variable B2 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B2)\n",
    "\n",
    "#b3\n",
    "qqnorm(dfAll$B3, main= \"B3\") # Distribucion de la variable B3 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B3)\n",
    "\n",
    "#b4\n",
    "qqnorm(dfAll$B4, main= \"B4\") # Distribucion de la variable B4 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B4)\n",
    "\n",
    "#b8\n",
    "qqnorm(dfAll$B8, main= \"B8\") # Distribucion de la variable B8 frente a su distribucion teorica normal\n",
    "qqline(dfAll$B8)\n",
    "\n",
    "# hist\n",
    "hist(dfAll$B2, main= \"B2\", col= \"blue\")\n",
    "hist(dfAll$B3, main= \"B3\", col= \"green\")\n",
    "hist(dfAll$B4, main= \"B4\", col= \"red\")\n",
    "hist(dfAll$B8, main= \"B8\", col= \"grey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEGMENTACIÓN DEL DATA SET\n",
    "\n",
    "A continuación se realiza una partición del data set original (dfAll). El conjunto de datos se divide en 70% para entrenamiento (dfTrain) y 30% para validación (dfTest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(1234)\n",
    "\n",
    "inBuild <- createDataPartition(y = dfAll$class, p = 0.7, list = FALSE)\n",
    "dfTest <- dfAll[-inBuild,] # 30% test\n",
    "dfTrain <- dfAll[inBuild,] # 70% test\n",
    "\n",
    "summary(dfTest)\n",
    "\n",
    "dummary(dfTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BALANCEADO DE LOS DATOS DE ENTRENAMIENTO\n",
    "\n",
    "Los algoritmos de machine learning presentan problemas cuando se enfrentan a conjuntos de datos desbalanceados. Si existe una gran diferencia en el número de muestras de cada categoria, puede que el clasificador no generalice bien para otros conjuntos de datos, generando modelos con overfitting o underfitting. Por ello es conveniente tener un número similar de muestras para cada categoria. En este caso se ha utilizado la técnica de submuestro, que consiste en eliminar datos de la categoría con menos muestras para compensar el número de muestras de ambas clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BALANCEADO DEL DATASET\n",
    "\n",
    "# funcion undersampling_df\n",
    "undersample_ds <- function(x, classCol, nsamples_class){\n",
    "  for (i in 1:length(unique(x[, classCol]))){\n",
    "    class.i <- unique(x[, classCol])[i]\n",
    "    if((sum(x[, classCol] == class.i) - nsamples_class) != 0){\n",
    "      x <- x[-sample(which(x[, classCol] == class.i), \n",
    "                     sum(x[, classCol] == class.i) - nsamples_class), ]\n",
    "    }\n",
    "  }\n",
    "  return(x)\n",
    "}\n",
    "\n",
    "# recuento de muestras por categoria\n",
    "desnudo <- sum(dfTrain$class == \"desnudo\") # 0 = desnudo\n",
    "cultivo <- sum(dfTrain$class == \"cultivo\") # 1 = cultivo\n",
    "\n",
    "desnudo\n",
    "cultivo\n",
    "\n",
    "#graf\n",
    "pie_values <- c(desnudo, cultivo)\n",
    "pie_labels <- c(\"desnudo\", \"cultivo\")\n",
    "\n",
    "pie(pie_values, pie_labels)\n",
    "\n",
    "# recorte del dataset\n",
    "sumatorio_clases <- c(desnudo, cultivo)\n",
    "\n",
    "nsamples_class <- min(sumatorio_clases)\n",
    "\n",
    "dfTrain_bal <- undersample_ds(dfTrain, \"class\", nsamples_class)\n",
    "\n",
    "# comprobacion\n",
    "desnudo_bal <- sum(dfTrain_bal$class == \"desnudo\") # 0 = desnud\n",
    "cultivo_bal <- sum(dfTrain_bal$class == \"cultivo\") # 1 = cultivo\n",
    "\n",
    "desnudo_bal\n",
    "cultivo_bal\n",
    "\n",
    "#graf\n",
    "pie_values_bal <- c(desnudo_bal, cultivo_bal)\n",
    "pie_labels_bal <- c(\"desnudo\", \"cultivo\")\n",
    "\n",
    "pie(pie_values_bal, pie_labels_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CLASIFICACIÓN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO DEL MODELO: ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set.seed(234)\n",
    "\n",
    "# ENTRENAMIENTO DEL MODELO\n",
    "\n",
    "# procesamiento en paralelo\n",
    "h2o.init(nthreads = -1)\n",
    "\n",
    "# red neuronal\n",
    "modFit_ANN = h2o.deeplearning(y = 'class',\n",
    "                              training_frame = as.h2o(dfTrain_bal),\n",
    "                              activation = 'Rectifier',\n",
    "                              hidden = c(3, 3),\n",
    "                              loss = \"CrossEntropy\"\n",
    "                              epochs = 80,\n",
    "                              rate = 0,03,\n",
    "                              train_samples_per_iteration = -2)\n",
    "\n",
    "# Default parameters:\n",
    "\n",
    "# retro-propagacion del error: Classic Backpropagation\n",
    "# momentum: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICCIÓN\n",
    "\n",
    "A continuación se realiza la predicción para el Dataset de validación (dfTest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_ANN <- h2o.predict(modFit_ANN, newdata = as.h2o(dfTest))\n",
    "\n",
    "pred_ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EVALUACION DEL MODELO\n",
    "\n",
    "# matriz de confusion\n",
    "yANN_pred <- as.vector(ifelse(pred_ANN$predict == 'desnudo', 0, 1))\n",
    "yANN_dfTest <- ifelse(dfTest$class == 'desnudo', 0, 1)\n",
    "\n",
    "conf_matrix <- table(yANN_dfTest, yANN_pred)\n",
    "\n",
    "conf_matrix\n",
    "\n",
    "# precision\n",
    "h2o.performance(modFit_ANN)\n",
    "\n",
    "# curva ROC\n",
    "pred1_ANN <- prediction(as.numeric(yANN_pred), as.numeric(yANN_dfTest))\n",
    "\n",
    "perf1_ANN <- performance(pred1_ANN, \"tpr\", \"fpr\")\n",
    "\n",
    "plot(perf1_ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CLASIFICACIÓN DE LA IMAGEN\n",
    "\n",
    "Finalmente se realiza la clasificación de la imagen raster según los dos tipos de coberturas (suelo desnudo / cultivaado) y se guarda el raster generado en el disco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CLAIFICACION DEL AREA DE ESTUDIO\n",
    "\n",
    "# clasificacion de la imagen\n",
    "beginCluster()\n",
    "system.time(raster_ANN <- clusterR(img, raster::predict, args= list(model = h2o.getFrame(modFit_ANN)))) #!\n",
    "endCluster()\n",
    "\n",
    "plot(raster_ANN)\n",
    "\n",
    "# guardar imagen en disco\n",
    "writeRaster(raster_ANN,\"raster_ANNpred.tiff\", drivername=\"Gtiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pause"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
